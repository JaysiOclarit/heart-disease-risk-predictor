{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa489f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (classification_report, roc_auc_score, RocCurveDisplay,\n",
    "                             precision_recall_curve, confusion_matrix, PrecisionRecallDisplay)\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d596b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- Data Cleaning ---------------\n",
    "\n",
    "df = pd.read_csv('data/heart_2020_uncleaned.csv')\n",
    "df.columns = df.columns.str.strip().str.replace(' ', '')\n",
    "df['HeartDisease'] = df['HeartDisease'].map({'Yes': 1, 'No': 0})\n",
    "df = df.apply(lambda x: x.str.strip().str.lower() if x.dtype == 'object' else x)\n",
    "\n",
    "target = 'HeartDisease'\n",
    "num_feats = ['BMI', 'PhysicalHealth', 'MentalHealth', 'SleepTime']\n",
    "cat_feats = [\n",
    "    'Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking', 'Sex',\n",
    "    'AgeCategory', 'Race', 'Diabetic', 'PhysicalActivity',\n",
    "    'GenHealth', 'Asthma', 'KidneyDisease', 'SkinCancer'\n",
    "]\n",
    "\n",
    "imbalance_ratio = (df[target] == 0).sum() / (df[target] == 1).sum()\n",
    "print(f\"Imbalance Ratio (Neg:Pos) = {imbalance_ratio:.2f}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[num_feats + cat_feats], df[target],\n",
    "    test_size=0.2, stratify=df[target], random_state=42\n",
    ")\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, num_feats),\n",
    "    ('cat', categorical_pipeline, cat_feats)\n",
    "])\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=imbalance_ratio\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pre', preproc),\n",
    "    ('clf', model)\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f'CV ROC-AUC: {scores.mean():.3f} Â± {scores.std():.3f}')\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b941cb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- Auto Summary & Visuals ---------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ðŸ“Œ MODEL SUMMARY & EVALUATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"\\nðŸ§¼ Missing Data (Top 10 Features):\")\n",
    "missing_summary = df.isna().mean().sort_values(ascending=False).head(10) * 100\n",
    "print(missing_summary.round(2).astype(str) + \" %\")\n",
    "\n",
    "print(\"\\nðŸ§¬ Feature Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nâš–ï¸ Class Distribution:\")\n",
    "class_counts = df['HeartDisease'].value_counts()\n",
    "print(class_counts)\n",
    "print(f\"Positive Rate (Heart Disease): {class_counts[1] / class_counts.sum():.2%}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Cross-Validated ROC-AUC: {scores.mean():.3f} Â± {scores.std():.3f}\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Classification Report (Default Threshold):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"\\nðŸ“ˆ Test ROC-AUC: {test_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ”§ Custom Threshold (~30% Recall): {custom_threshold:.2f}\")\n",
    "y_pred_custom = (y_proba >= custom_threshold).astype(int)\n",
    "print(\"\\nðŸ“‹ Classification Report (Adjusted Threshold):\")\n",
    "print(classification_report(y_test, y_pred_custom))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_custom)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "print(f\"True Negatives: {tn}, False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}, True Positives: {tp}\")\n",
    "\n",
    "accuracy = (tp + tn) / cm.sum()\n",
    "recall = tp / (tp + fn)\n",
    "precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "print(f\"\\nâœ… Adjusted Accuracy: {accuracy:.3f}\")\n",
    "print(f\"âœ… Adjusted Recall (Sensitivity): {recall:.3f}\")\n",
    "print(f\"âœ… Adjusted Precision: {precision_val:.3f}\")\n",
    "\n",
    "# Visuals\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "plt.title('ROC Curve â€“ Heart Disease Risk Model')\n",
    "plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_proba)\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Adjusted Threshold)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\nðŸ”‘ Top Influential Features:\")\n",
    "ohe = pipe.named_steps['pre'].named_transformers_['cat'].named_steps['encoder']\n",
    "encoded_feats = ohe.get_feature_names_out(cat_feats)\n",
    "final_feats = num_feats + list(encoded_feats)\n",
    "\n",
    "feat_importance = pipe.named_steps['clf'].feature_importances_\n",
    "importance_df = pd.DataFrame({\"Feature\": final_feats, \"Importance\": feat_importance})\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(importance_df.head(15))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=importance_df.head(15), x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Top 15 Most Important Features')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e674d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "joblib.dump(pipe, 'model/best_heart_disease_model.joblib')\n",
    "print(\"Model saved to 'model/best_heart_disease_model.joblib'\")\n",
    "\n",
    "meta = {\n",
    "    \"num_feats\": num_feats,\n",
    "    \"cat_feats\": cat_feats,\n",
    "    \"all_feats\": final_feats,\n",
    "    \"target\": target\n",
    "}\n",
    "json.dump(meta, open('model/feature_metadata.json', 'w'))\n",
    "print(\"Feature metadata saved to 'model/feature_metadata.json'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
